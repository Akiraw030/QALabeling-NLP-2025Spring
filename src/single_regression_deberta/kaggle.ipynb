{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Kaggle Inference Notebook (Single Regression + 4 Post-Processing Strategies)\n",
    "# ====================================================\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import rankdata\n",
    "import html\n",
    "\n",
    "# ------------------- 配置 (Configuration) -------------------\n",
    "class CFG:\n",
    "    # 您的訓練權重路徑\n",
    "    model_dir = \"/kaggle/input/deberta-finetuned/pytorch/arch1/10\" \n",
    "    \n",
    "    # Tokenizer 路徑\n",
    "    base_model = \"/kaggle/input/deberta-tokenizer/deberta-v3-base-tokenizer\" \n",
    "    \n",
    "    pooling_strategy = 'arch1_6groups' \n",
    "    \n",
    "    # 【關鍵開關】選擇後處理方式\n",
    "    # Options: 'raw', 'optimized', 'voters', 'distribution'\n",
    "    post_processing = 'voters' \n",
    "    \n",
    "    max_len = 512\n",
    "    batch_size = 16\n",
    "    num_workers = 2\n",
    "    seed = 42\n",
    "    n_fold = 5\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "TARGET_COLS = [\n",
    "    'question_asker_intent_understanding', 'question_body_critical', 'question_conversational',\n",
    "    'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
    "    'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent',\n",
    "    'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
    "    'question_type_compare', 'question_type_consequence', 'question_type_definition',\n",
    "    'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
    "    'question_type_reason_explanation', 'question_type_spelling', 'question_well_written',\n",
    "    'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "    'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure',\n",
    "    'answer_type_reason_explanation', 'answer_well_written'\n",
    "]\n",
    "\n",
    "# ------------------- 資料處理 -------------------\n",
    "def modern_preprocess(text):\n",
    "    if pd.isna(text): return \"\"\n",
    "    text = str(text)\n",
    "    text = html.unescape(text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "class QuestDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=512):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.questions = [\n",
    "            modern_preprocess(t) + \" \" + modern_preprocess(b) \n",
    "            for t, b in zip(df['question_title'].values, df['question_body'].values)\n",
    "        ]\n",
    "        self.answers = [modern_preprocess(a) for a in df['answer'].values]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        answer = self.answers[idx]\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            question,\n",
    "            answer,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "        if 'token_type_ids' in inputs:\n",
    "            item['token_type_ids'] = torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n",
    "            \n",
    "        return item\n",
    "\n",
    "# ------------------- 模型定義 (Single Regression) -------------------\n",
    "class QuestModel(nn.Module):\n",
    "    def __init__(self, model_name, num_targets, pooling_strategy='arch1', dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.pooling_strategy = pooling_strategy\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        if pooling_strategy in ['arch2', 'cls_all']:\n",
    "            self.config.update({'output_hidden_states': True})\n",
    "            \n",
    "        self.backbone = AutoModel.from_config(self.config)\n",
    "        hidden_size = self.config.hidden_size\n",
    "        \n",
    "        self.idx_g1 = [3, 4, 5, 16, 17]          \n",
    "        self.idx_g2 = [0, 1, 6, 7, 20]           \n",
    "        self.idx_g3 = [2, 10]                    \n",
    "        self.idx_g4 = [8, 9, 11, 12, 13, 14, 15, 18, 19] \n",
    "        self.idx_g5 = [26, 27]                   \n",
    "        self.idx_g6 = [21, 22, 23, 24, 25, 28, 29] \n",
    "        \n",
    "        if self.pooling_strategy == 'mean':\n",
    "            self.fc = nn.Linear(hidden_size, num_targets)\n",
    "            \n",
    "        elif self.pooling_strategy == 'arch1':\n",
    "            self.q_head = self._make_head(hidden_size * 3, 21, dropout_rate)\n",
    "            self.a_head = self._make_head(hidden_size * 3, 9, dropout_rate)\n",
    "            \n",
    "        elif self.pooling_strategy == 'arch1_6groups':\n",
    "            self.head_g1 = self._make_head(hidden_size * 3, len(self.idx_g1), dropout_rate)\n",
    "            self.head_g2 = self._make_head(hidden_size * 3, len(self.idx_g2), dropout_rate)\n",
    "            self.head_g3 = self._make_head(hidden_size * 3, len(self.idx_g3), dropout_rate)\n",
    "            self.head_g4 = self._make_head(hidden_size * 3, len(self.idx_g4), dropout_rate)\n",
    "            self.head_g5 = self._make_head(hidden_size * 3, len(self.idx_g5), dropout_rate)\n",
    "            self.head_g6 = self._make_head(hidden_size * 3, len(self.idx_g6), dropout_rate)\n",
    "\n",
    "        elif self.pooling_strategy == 'arch2':\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(hidden_size * 4, num_targets)\n",
    "            )\n",
    "\n",
    "        elif self.pooling_strategy == 'cls_all':\n",
    "            # Concatenate CLS tokens from all hidden layers\n",
    "            # num_hidden_layers = 12 for DeBERTa-v3-base\n",
    "            # +1 for embedding layer\n",
    "            num_hidden_states = self.config.num_hidden_layers + 1\n",
    "            cls_concat_dim = hidden_size * num_hidden_states\n",
    "            \n",
    "            self.head_g1 = self._make_head(cls_concat_dim, len(self.idx_g1), dropout_rate)\n",
    "            self.head_g2 = self._make_head(cls_concat_dim, len(self.idx_g2), dropout_rate)\n",
    "            self.head_g3 = self._make_head(cls_concat_dim, len(self.idx_g3), dropout_rate)\n",
    "            self.head_g4 = self._make_head(cls_concat_dim, len(self.idx_g4), dropout_rate)\n",
    "            self.head_g5 = self._make_head(cls_concat_dim, len(self.idx_g5), dropout_rate)\n",
    "            self.head_g6 = self._make_head(cls_concat_dim, len(self.idx_g6), dropout_rate)\n",
    "\n",
    "        elif self.pooling_strategy == 'mlp_only':\n",
    "            # MLP that reduces sequence length dimension to 1\n",
    "            self.mlp = nn.Sequential(\n",
    "                nn.Linear(512, hidden_size // 2),\n",
    "                nn.Tanh(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(hidden_size // 2, 1)\n",
    "            )\n",
    "            self.head_g1 = self._make_head(hidden_size, len(self.idx_g1), dropout_rate)\n",
    "            self.head_g2 = self._make_head(hidden_size, len(self.idx_g2), dropout_rate)\n",
    "            self.head_g3 = self._make_head(hidden_size, len(self.idx_g3), dropout_rate)\n",
    "            self.head_g4 = self._make_head(hidden_size, len(self.idx_g4), dropout_rate)\n",
    "            self.head_g5 = self._make_head(hidden_size, len(self.idx_g5), dropout_rate)\n",
    "            self.head_g6 = self._make_head(hidden_size, len(self.idx_g6), dropout_rate)\n",
    "\n",
    "    def _make_head(self, input_dim, output_dim, dropout_rate):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_dim, self.config.hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(self.config.hidden_size, output_dim)\n",
    "        )\n",
    "\n",
    "    def _masked_mean_pooling(self, hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "    def _get_pooling_features(self, last_hidden_state, attention_mask, token_type_ids):\n",
    "        cls_token = last_hidden_state[:, 0, :]\n",
    "        global_avg = self._masked_mean_pooling(last_hidden_state, attention_mask)\n",
    "        \n",
    "        if token_type_ids is None:\n",
    "            q_avg = global_avg; a_avg = global_avg\n",
    "        else:\n",
    "            q_mask = attention_mask * (1 - token_type_ids)\n",
    "            q_avg = self._masked_mean_pooling(last_hidden_state, q_mask)\n",
    "            a_mask = attention_mask * token_type_ids\n",
    "            a_avg = self._masked_mean_pooling(last_hidden_state, a_mask)\n",
    "            \n",
    "        return cls_token, global_avg, q_avg, a_avg\n",
    "\n",
    "    def _pool_arch2(self, all_hidden_states):\n",
    "        last_4_layers = all_hidden_states[-4:]\n",
    "        cls_embeddings = [layer[:, 0, :] for layer in last_4_layers]\n",
    "        return torch.cat(cls_embeddings, dim=1)\n",
    "    \n",
    "    def _pool_cls_concat(self, all_hidden_states):\n",
    "        '''Concatenate CLS tokens from all hidden layers'''\n",
    "        # all_hidden_states: tuple of (num_layers,), each [batch, seq_len, hidden]\n",
    "        cls_embeddings = [layer[:, 0, :] for layer in all_hidden_states]\n",
    "        return torch.cat(cls_embeddings, dim=1)  # [batch, hidden * num_layers]\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        \n",
    "        if self.pooling_strategy == 'mean':\n",
    "            feature = self._masked_mean_pooling(outputs.last_hidden_state, attention_mask)\n",
    "            output = self.fc(feature)\n",
    "            \n",
    "        elif self.pooling_strategy == 'arch1':\n",
    "            cls, glob, q, a = self._get_pooling_features(last_hidden_state, attention_mask, token_type_ids)\n",
    "            q_feat = torch.cat([cls, glob, q], dim=1)\n",
    "            a_feat = torch.cat([cls, glob, a], dim=1)\n",
    "            output = torch.cat([self.q_head(q_feat), self.a_head(a_feat)], dim=1)\n",
    "            \n",
    "        elif self.pooling_strategy == 'arch1_6groups':\n",
    "            cls, glob, q, a = self._get_pooling_features(last_hidden_state, attention_mask, token_type_ids)\n",
    "            feat_pure_q = torch.cat([cls, glob, q], dim=1)\n",
    "            feat_pure_a = torch.cat([cls, glob, a], dim=1)\n",
    "            \n",
    "            out_g1 = self.head_g1(feat_pure_q)\n",
    "            out_g2 = self.head_g2(feat_pure_q)\n",
    "            out_g3 = self.head_g3(feat_pure_q)\n",
    "            out_g4 = self.head_g4(feat_pure_q)\n",
    "            out_g5 = self.head_g5(feat_pure_a)\n",
    "            out_g6 = self.head_g6(feat_pure_a)\n",
    "            \n",
    "            batch_size = input_ids.size(0)\n",
    "            output = torch.zeros(batch_size, 30, dtype=out_g1.dtype, device=input_ids.device)\n",
    "            output[:, self.idx_g1] = out_g1\n",
    "            output[:, self.idx_g2] = out_g2\n",
    "            output[:, self.idx_g3] = out_g3\n",
    "            output[:, self.idx_g4] = out_g4\n",
    "            output[:, self.idx_g5] = out_g5\n",
    "            output[:, self.idx_g6] = out_g6\n",
    "            \n",
    "        elif self.pooling_strategy == 'arch2':\n",
    "            feature = self._pool_arch2(outputs.hidden_states)\n",
    "            output = self.fc(feature)\n",
    "\n",
    "        elif self.pooling_strategy == 'cls_all':\n",
    "            # Concatenate CLS tokens from all hidden layers, feed into 6 heads\n",
    "            a_feat = self._pool_cls_concat(outputs.hidden_states)\n",
    "            \n",
    "            # Pass through 6 heads\n",
    "            out_g1 = self.head_g1(a_feat)\n",
    "            out_g2 = self.head_g2(a_feat)\n",
    "            out_g3 = self.head_g3(a_feat)\n",
    "            out_g4 = self.head_g4(a_feat)\n",
    "            out_g5 = self.head_g5(a_feat)\n",
    "            out_g6 = self.head_g6(a_feat)\n",
    "            \n",
    "            # Re-assemble output\n",
    "            batch_size = input_ids.size(0)\n",
    "            output = torch.zeros(batch_size, 30, dtype=out_g1.dtype, device=input_ids.device)\n",
    "            \n",
    "            output[:, self.idx_g1] = out_g1\n",
    "            output[:, self.idx_g2] = out_g2\n",
    "            output[:, self.idx_g3] = out_g3\n",
    "            output[:, self.idx_g4] = out_g4\n",
    "            output[:, self.idx_g5] = out_g5\n",
    "            output[:, self.idx_g6] = out_g6\n",
    "\n",
    "        elif self.pooling_strategy == 'mlp_only':\n",
    "            batch_size, seq_len, hidden = last_hidden_state.shape\n",
    "            transposed = last_hidden_state.transpose(1, 2)\n",
    "            reduced = self.mlp(transposed)\n",
    "            a_feat = reduced.squeeze(-1)\n",
    "            \n",
    "            out_g1 = self.head_g1(a_feat)\n",
    "            out_g2 = self.head_g2(a_feat)\n",
    "            out_g3 = self.head_g3(a_feat)\n",
    "            out_g4 = self.head_g4(a_feat)\n",
    "            out_g5 = self.head_g5(a_feat)\n",
    "            out_g6 = self.head_g6(a_feat)\n",
    "            \n",
    "            output = torch.zeros(batch_size, 30, dtype=out_g1.dtype, device=input_ids.device)\n",
    "            output[:, self.idx_g1] = out_g1\n",
    "            output[:, self.idx_g2] = out_g2\n",
    "            output[:, self.idx_g3] = out_g3\n",
    "            output[:, self.idx_g4] = out_g4\n",
    "            output[:, self.idx_g5] = out_g5\n",
    "            output[:, self.idx_g6] = out_g6\n",
    "            \n",
    "        return output\n",
    "\n",
    "# ------------------- Post-Processing Strategies -------------------\n",
    "\n",
    "# 1. Optimized Rounder (閾值截斷)\n",
    "class OptimizedRounder:\n",
    "    def __init__(self):\n",
    "        self.coef_ = [0.05, 0.95]\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.nan_to_num(X, nan=0.5)\n",
    "        X_p = np.copy(X)\n",
    "        low, high = self.coef_[0], self.coef_[1]\n",
    "        X_p = np.clip(X_p, low, high)\n",
    "        if np.unique(X_p).size == 1:\n",
    "            eps = 1e-6\n",
    "            max_idx = np.argmax(X)\n",
    "            X_p[max_idx] += eps\n",
    "        return X_p\n",
    "\n",
    "# 2. Voters Rounder (網格吸附 - 防呆修正版)\n",
    "class VotersRounder:\n",
    "    def __init__(self, train_vals, dev_threshold=0.01):\n",
    "        \"\"\"\n",
    "        Voters Rounder with deviation-based fallback\n",
    "        \n",
    "        Args:\n",
    "            train_vals: Training values to build the grid\n",
    "            dev_threshold: Standard deviation threshold. If snapped values have \n",
    "                          deviation below this, return original predictions\n",
    "        \"\"\"\n",
    "        # 過濾掉可能的 NaN，確保網格乾淨\n",
    "        clean_vals = train_vals[~np.isnan(train_vals)]\n",
    "        self.unique_vals = np.sort(np.unique(clean_vals))\n",
    "        self.dev_threshold = dev_threshold\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # 1. 清理輸入 NaN\n",
    "        X_clean = np.nan_to_num(X, nan=0.5)\n",
    "        \n",
    "        # 2. 吸附到網格 (Snap to Grid)\n",
    "        idx = np.abs(X_clean[:, None] - self.unique_vals[None, :]).argmin(axis=1)\n",
    "        X_p = self.unique_vals[idx]\n",
    "        \n",
    "        # 3. 【改進】檢查標準差是否太小\n",
    "        # 如果吸附後的標準差小於閾值，代表網格太粗，回傳原始預測值\n",
    "        deviation = np.std(X_p)\n",
    "        if deviation < self.dev_threshold:\n",
    "            return X_clean\n",
    "            \n",
    "        return X_p\n",
    "\n",
    "# 3. Distribution Rounder (分佈擬合)\n",
    "class DistributionRounder:\n",
    "    def __init__(self, train_vals):\n",
    "        # 儲存訓練集的分佈 (排序後)\n",
    "        self.train_vals = np.sort(train_vals)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # 1. 取得預測值的排名 (0 ~ 1)\n",
    "        # argsort twice 得到 rank\n",
    "        n = len(X)\n",
    "        ranks = rankdata(X, method='ordinal') - 1\n",
    "        \n",
    "        # 2. 對映回訓練集的值 (Quantile Mapping)\n",
    "        return np.interp(\n",
    "            np.linspace(0, 1, n),\n",
    "            np.linspace(0, 1, len(self.train_vals)),\n",
    "            self.train_vals\n",
    "        )[ranks]\n",
    "\n",
    "# ------------------- Inference Logic -------------------\n",
    "def inference_fn(test_loader, model, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch.get('token_type_ids')\n",
    "            if token_type_ids is not None:\n",
    "                token_type_ids = token_type_ids.to(device)\n",
    "            \n",
    "            y_preds = model(input_ids, attention_mask, token_type_ids)\n",
    "            preds.append(y_preds.sigmoid().cpu().numpy())\n",
    "            \n",
    "    return np.concatenate(preds)\n",
    "\n",
    "# ------------------- Main -------------------\n",
    "if __name__ == '__main__':\n",
    "    TEST_PATH = 'test.csv'\n",
    "    TRAIN_PATH = 'train.csv' # 用於後處理學習分佈\n",
    "    \n",
    "    # Kaggle 路徑檢查\n",
    "    if not os.path.exists(TEST_PATH):\n",
    "        TEST_PATH = '/kaggle/input/google-quest-challenge/test.csv'\n",
    "        TRAIN_PATH = '/kaggle/input/google-quest-challenge/train.csv'\n",
    "    \n",
    "    test = pd.read_csv(TEST_PATH)\n",
    "    train = pd.read_csv(TRAIN_PATH)\n",
    "    \n",
    "    print(f\"Test Shape: {test.shape}, Train Shape: {train.shape}\")\n",
    "    print(f\"Selected Post-Processing Strategy: {CFG.post_processing}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.base_model)\n",
    "    test_dataset = QuestDataset(test, tokenizer, max_len=CFG.max_len)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=CFG.batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # 尋找模型\n",
    "    weight_paths = []\n",
    "    for fold in range(CFG.n_fold):\n",
    "        path = os.path.join(CFG.model_dir, f\"deberta_v3_fold{fold}_best.pth\")\n",
    "        if os.path.exists(path): weight_paths.append(path)\n",
    "    if os.path.exists(os.path.join(CFG.model_dir, \"deberta_v3_single_run_best.pth\")):\n",
    "        weight_paths.append(os.path.join(CFG.model_dir, \"deberta_v3_single_run_best.pth\"))\n",
    "        \n",
    "    if not weight_paths:\n",
    "        print(\"No weights found!\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    print(f\"Ensembling {len(weight_paths)} models...\")\n",
    "    \n",
    "    model_preds = []\n",
    "    for weight_path in weight_paths:\n",
    "        model = QuestModel(\n",
    "            CFG.base_model, \n",
    "            num_targets=len(TARGET_COLS), \n",
    "            pooling_strategy=CFG.pooling_strategy\n",
    "        )\n",
    "        model.load_state_dict(torch.load(weight_path, map_location=CFG.device))\n",
    "        model.to(CFG.device)\n",
    "        \n",
    "        preds = inference_fn(test_loader, model, CFG.device)\n",
    "        model_preds.append(preds)\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    if len(model_preds) > 0:\n",
    "        # 1. 取得平均預測\n",
    "        avg_preds = np.mean(model_preds, axis=0)\n",
    "        final_preds = np.zeros_like(avg_preds)\n",
    "        \n",
    "        # 2. 應用選擇的後處理策略\n",
    "        print(f\"Applying Post-Processing: {CFG.post_processing}\")\n",
    "        \n",
    "        for i, col in enumerate(TARGET_COLS):\n",
    "            # 原始訓練數據 (供 Distribution/Voters 參考)\n",
    "            train_col_values = train[col].values\n",
    "            # 當前欄位的預測值\n",
    "            curr_preds = avg_preds[:, i]\n",
    "            \n",
    "            if CFG.post_processing == 'raw':\n",
    "                final_preds[:, i] = curr_preds\n",
    "                \n",
    "            elif CFG.post_processing == 'optimized':\n",
    "                opt = OptimizedRounder()\n",
    "                final_preds[:, i] = opt.predict(curr_preds)\n",
    "                \n",
    "            elif CFG.post_processing == 'voters':\n",
    "                voter = VotersRounder(train_col_values)\n",
    "                final_preds[:, i] = voter.predict(curr_preds)\n",
    "                \n",
    "            elif CFG.post_processing == 'distribution':\n",
    "                dist_rounder = DistributionRounder(train_col_values)\n",
    "                final_preds[:, i] = dist_rounder.predict(curr_preds)\n",
    "        \n",
    "        submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "        submission[TARGET_COLS] = final_preds\n",
    "        submission.to_csv('submission.csv', index=False)\n",
    "        print(\"submission.csv saved successfully!\")\n",
    "    else:\n",
    "        print(\"Error: No predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 828965,
     "sourceId": 7968,
     "sourceType": "competition"
    },
    {
     "datasetId": 8889245,
     "sourceId": 13946897,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 521159,
     "modelInstanceId": 506367,
     "sourceId": 668898,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
